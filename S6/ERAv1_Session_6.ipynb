{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a3b961-15d5-493d-f4b2-eb798a79aa81"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 263816992.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31252758.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 151664285.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6258386.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net_0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)           #input - 7, Output 5, RF\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)          #input - 5, Output 3, RF\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)           #input - 3, Output 1, RF\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_0\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "# 10: Test set: Average loss: 0.2577, Accuracy: 8935/10000 (89%)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTEvOlzDAxTE",
        "outputId": "4fed902f-b503-43c4-eb56-8d939ac646c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b72feb762c6a>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Relu before the last layer\n",
        "\n",
        "class Net_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)           #input - 7, Output 5, RF\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)          #input - 5, Output 3, RF\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)           #input - 3, Output 1, RF\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = self.conv7(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_1\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "# 10: Test set: Average loss: 0.0281, Accuracy: 9916/10000 (99%)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neUWvNWqDSMY",
        "outputId": "022ce43e-66ac-443b-adca-99cf30264c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-97bb41efa4e8>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace FCs by 1x1x256x10 + GAP\n",
        "\n",
        "class Net_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 10, 1)            #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)                    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_2\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "# 10: Test set: Average loss: 0.0533, Accuracy: 9837/10000 (98%)\n",
        "# 20: Test set: Average loss: 0.0283, Accuracy: 9900/10000 (99%)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcKeenJxD815",
        "outputId": "46830bd0-7cd7-40f1-a858-91d3d6e7d6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7             [-1, 10, 7, 7]           2,570\n",
            "         AvgPool2d-8             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 390,410\n",
            "Trainable params: 390,410\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.34\n",
            "Params size (MB): 1.49\n",
            "Estimated Total Size (MB): 2.84\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-004b74ddca23>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove conv4. max 64 ch\n",
        "\n",
        "class Net_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)     #input - 28, Output 28, RF\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)   #input - 14, Output 14, RF\n",
        "        # self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 10, 1)              #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)                    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_3\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "# 10: Test set: Average loss: 0.1315, Accuracy: 9608/10000 (96%)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ppMCYVJHLP5",
        "outputId": "96c1ab8d-ed34-4c57-f0dd-1d6ab9dc40a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4           [-1, 64, 14, 14]          36,928\n",
            "         MaxPool2d-5             [-1, 64, 7, 7]               0\n",
            "            Conv2d-6             [-1, 10, 7, 7]             650\n",
            "         AvgPool2d-7             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 56,394\n",
            "Trainable params: 56,394\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.79\n",
            "Params size (MB): 0.22\n",
            "Estimated Total Size (MB): 1.01\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-1c5ab9dea573>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add BN\n",
        "\n",
        "class Net_4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)     #input - 28, Output 28, RF\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)   #input - 14, Output 14, RF\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        # self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 10, 1)              #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)                    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
        "        x = self.pool2(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_4\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "#epoch: 10\n",
        "#loss=0.03565816953778267 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n",
        "#Test set: Average loss: 0.1311, Accuracy: 9607/10000 (96%)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtqJsFxZLTtQ",
        "outputId": "42f6f35f-1788-4ac8-db23-b6946489b57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "            Conv2d-3           [-1, 64, 28, 28]          18,496\n",
            "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
            "         MaxPool2d-5           [-1, 64, 14, 14]               0\n",
            "            Conv2d-6           [-1, 64, 14, 14]          36,928\n",
            "       BatchNorm2d-7           [-1, 64, 14, 14]             128\n",
            "         MaxPool2d-8             [-1, 64, 7, 7]               0\n",
            "            Conv2d-9             [-1, 10, 7, 7]             650\n",
            "        AvgPool2d-10             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 56,714\n",
            "Trainable params: 56,714\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.46\n",
            "Params size (MB): 0.22\n",
            "Estimated Total Size (MB): 1.68\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c3895eceecbc>:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add BN to Net_2\n",
        "\n",
        "class Net_5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 10, 1)            #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)                    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
        "        x = self.pool2(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_5\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "#epoch: 10\n",
        "#loss=0.019351879134774208 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.98it/s]\n",
        "#Test set: Average loss: 0.0452, Accuracy: 9850/10000 (98%)\n",
        "\n",
        "#epoch: 19\n",
        "#loss=0.0030171473044902086 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.02it/s]\n",
        "#Test set: Average loss: 0.0286, Accuracy: 9914/10000 (99%)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uuvRUyuOqV6",
        "outputId": "ee45df49-0522-42a8-9e8d-065035e31370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "            Conv2d-3           [-1, 64, 28, 28]          18,496\n",
            "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
            "         MaxPool2d-5           [-1, 64, 14, 14]               0\n",
            "            Conv2d-6          [-1, 128, 14, 14]          73,856\n",
            "       BatchNorm2d-7          [-1, 128, 14, 14]             256\n",
            "            Conv2d-8          [-1, 256, 14, 14]         295,168\n",
            "       BatchNorm2d-9          [-1, 256, 14, 14]             512\n",
            "        MaxPool2d-10            [-1, 256, 7, 7]               0\n",
            "           Conv2d-11             [-1, 10, 7, 7]           2,570\n",
            "        AvgPool2d-12             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 391,370\n",
            "Trainable params: 391,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 2.49\n",
            "Params size (MB): 1.49\n",
            "Estimated Total Size (MB): 3.99\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e21bbe09ed1e>:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add dropout\n",
        "\n",
        "class Net_6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 10, 1)            #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)          \n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.05)\n",
        "        self.dropout2 = nn.Dropout(0.05)\n",
        "        self.dropout3 = nn.Dropout(0.05)\n",
        "        self.dropout4 = nn.Dropout(0.05)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_6\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n",
        "#epoch: 10\n",
        "#loss=0.016568930819630623 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.46it/s]\n",
        "#Test set: Average loss: 0.0456, Accuracy: 9866/10000 (99%)\n",
        "\n",
        "#epoch: 20\n",
        "#loss=0.008861390873789787 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.52it/s]\n",
        "#Test set: Average loss: 0.0351, Accuracy: 9891/10000 (99%)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WraBd5GdQZy3",
        "outputId": "4a99046c-1a4e-4443-b2e8-dea5da611dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "           Dropout-3           [-1, 32, 28, 28]               0\n",
            "            Conv2d-4           [-1, 64, 28, 28]          18,496\n",
            "       BatchNorm2d-5           [-1, 64, 28, 28]             128\n",
            "           Dropout-6           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-7           [-1, 64, 14, 14]               0\n",
            "            Conv2d-8          [-1, 128, 14, 14]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 14, 14]             256\n",
            "          Dropout-10          [-1, 128, 14, 14]               0\n",
            "           Conv2d-11          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
            "          Dropout-13          [-1, 256, 14, 14]               0\n",
            "        MaxPool2d-14            [-1, 256, 7, 7]               0\n",
            "           Conv2d-15             [-1, 10, 7, 7]           2,570\n",
            "        AvgPool2d-16             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 391,370\n",
            "Trainable params: 391,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.64\n",
            "Params size (MB): 1.49\n",
            "Estimated Total Size (MB): 5.14\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-c24d52b133e8>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Larger dropout\n",
        "\n",
        "class Net_7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 10, 1)            #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)          \n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "        self.dropout4 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_7\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n",
        "#epoch: 10\n",
        "#loss=0.007140759844332933 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s]\n",
        "#Test set: Average loss: 0.0569, Accuracy: 9839/10000 (98%)\n",
        "\n",
        "#epoch: 20\n",
        "#loss=0.024968238547444344 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.36it/s]\n",
        "#Test set: Average loss: 0.0469, Accuracy: 9878/10000 (99%)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRGLFukfZDSB",
        "outputId": "02be5927-1080-4585-f638-d88195927a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "           Dropout-3           [-1, 32, 28, 28]               0\n",
            "            Conv2d-4           [-1, 64, 28, 28]          18,496\n",
            "       BatchNorm2d-5           [-1, 64, 28, 28]             128\n",
            "           Dropout-6           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-7           [-1, 64, 14, 14]               0\n",
            "            Conv2d-8          [-1, 128, 14, 14]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 14, 14]             256\n",
            "          Dropout-10          [-1, 128, 14, 14]               0\n",
            "           Conv2d-11          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
            "          Dropout-13          [-1, 256, 14, 14]               0\n",
            "        MaxPool2d-14            [-1, 256, 7, 7]               0\n",
            "           Conv2d-15             [-1, 10, 7, 7]           2,570\n",
            "        AvgPool2d-16             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 391,370\n",
            "Trainable params: 391,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.64\n",
            "Params size (MB): 1.49\n",
            "Estimated Total Size (MB): 5.14\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c908b5d6768b>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cross_entropy instead of log_softmax\n",
        "\n",
        "class Net_8(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 10, 1)            #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)          \n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "        self.dropout4 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        # return F.log_softmax(x)\n",
        "        return x\n",
        "\n",
        "Net = Net_8\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "def train_ce(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test_ce(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "  \n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    print(f'epoch: {epoch}')\n",
        "    train_ce(model, device, train_loader, optimizer, epoch)\n",
        "    test_ce(model, device, test_loader)\n",
        "\n",
        "#stopped early\n",
        "# 59% accuracy at epoch 8\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1J-Au8i4AI-h",
        "outputId": "2c325b7b-bed8-4451-e16c-3a5b5dd095f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-f93bebd886db>:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "           Dropout-3           [-1, 32, 28, 28]               0\n",
            "            Conv2d-4           [-1, 64, 28, 28]          18,496\n",
            "       BatchNorm2d-5           [-1, 64, 28, 28]             128\n",
            "           Dropout-6           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-7           [-1, 64, 14, 14]               0\n",
            "            Conv2d-8          [-1, 128, 14, 14]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 14, 14]             256\n",
            "          Dropout-10          [-1, 128, 14, 14]               0\n",
            "           Conv2d-11          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
            "          Dropout-13          [-1, 256, 14, 14]               0\n",
            "        MaxPool2d-14            [-1, 256, 7, 7]               0\n",
            "           Conv2d-15             [-1, 10, 7, 7]           2,570\n",
            "        AvgPool2d-16             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 391,370\n",
            "Trainable params: 391,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.64\n",
            "Params size (MB): 1.49\n",
            "Estimated Total Size (MB): 5.14\n",
            "----------------------------------------------------------------\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.9399456977844238 batch_id=468: 100%|██████████| 469/469 [00:26<00:00, 17.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0766, Accuracy: 4179/10000 (42%)\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.9392457008361816 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9795, Accuracy: 5161/10000 (52%)\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.874040126800537 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9470, Accuracy: 5371/10000 (54%)\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.8725895881652832 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8817, Accuracy: 5891/10000 (59%)\n",
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.8879324197769165 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8901, Accuracy: 5785/10000 (58%)\n",
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.870354175567627 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9181, Accuracy: 5555/10000 (56%)\n",
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.882435917854309 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8845, Accuracy: 5809/10000 (58%)\n",
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.8869620561599731 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8712, Accuracy: 5914/10000 (59%)\n",
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.8777079582214355 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8718, Accuracy: 5914/10000 (59%)\n",
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.821074366569519 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8707, Accuracy: 5911/10000 (59%)\n",
            "\n",
            "epoch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.8039277791976929 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8696, Accuracy: 5922/10000 (59%)\n",
            "\n",
            "epoch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.838909387588501 batch_id=216:  46%|████▋     | 217/469 [00:10<00:12, 20.79it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f93bebd886db>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtrain_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mtest_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f93bebd886db>\u001b[0m in \u001b[0;36mtrain_ce\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cross_entropy instead of log_softmax, use Adam\n",
        "\n",
        "class Net_9(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input - 28, Output 28, RF\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               \n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input - 14, Output 14, RF\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 10, 1)            #input - 7, Output 7, RF\n",
        "        self.gap = nn.AvgPool2d(7)          \n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "        self.dropout4 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        # return F.log_softmax(x)\n",
        "        return x\n",
        "\n",
        "Net = Net_9\n",
        "\n",
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "def train_ce(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test_ce(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "  \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    print(f'epoch: {epoch}')\n",
        "    train_ce(model, device, train_loader, optimizer, epoch)\n",
        "    test_ce(model, device, test_loader)\n",
        "\n",
        "#stopped early\n",
        "# 59% accuracy at epoch 8\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pWlFCjYGGl3",
        "outputId": "a98e2eed-1ac9-46eb-8437-c01984eeeca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "           Dropout-3           [-1, 32, 28, 28]               0\n",
            "            Conv2d-4           [-1, 64, 28, 28]          18,496\n",
            "       BatchNorm2d-5           [-1, 64, 28, 28]             128\n",
            "           Dropout-6           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-7           [-1, 64, 14, 14]               0\n",
            "            Conv2d-8          [-1, 128, 14, 14]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 14, 14]             256\n",
            "          Dropout-10          [-1, 128, 14, 14]               0\n",
            "           Conv2d-11          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
            "          Dropout-13          [-1, 256, 14, 14]               0\n",
            "        MaxPool2d-14            [-1, 256, 7, 7]               0\n",
            "           Conv2d-15             [-1, 10, 7, 7]           2,570\n",
            "        AvgPool2d-16             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 391,370\n",
            "Trainable params: 391,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.64\n",
            "Params size (MB): 1.49\n",
            "Estimated Total Size (MB): 5.14\n",
            "----------------------------------------------------------------\n",
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.429561734199524 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4627, Accuracy: 3963/10000 (40%)\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.3300385475158691 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4318, Accuracy: 3973/10000 (40%)\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.4826914072036743 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4328, Accuracy: 3967/10000 (40%)\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.6205140352249146 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4166, Accuracy: 3974/10000 (40%)\n",
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.5827418565750122 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4145, Accuracy: 3996/10000 (40%)\n",
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.6059070825576782 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4076, Accuracy: 3998/10000 (40%)\n",
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.35227632522583 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4086, Accuracy: 3995/10000 (40%)\n",
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.5904473066329956 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4127, Accuracy: 3993/10000 (40%)\n",
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.6327377557754517 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4140, Accuracy: 3993/10000 (40%)\n",
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.5272210836410522 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4089, Accuracy: 3989/10000 (40%)\n",
            "\n",
            "epoch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=1.5360075235366821 batch_id=135:  29%|██▉       | 136/469 [00:06<00:15, 21.55it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-baf251fdf897>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtrain_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mtest_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-baf251fdf897>\u001b[0m in \u001b[0;36mtrain_ce\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccff340-7b73-410a-cb69-b45aeb2a91d8"
      },
      "source": [
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    print(f'epoch: {epoch}')\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-14-f3131be26054>:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "loss=0.089035265147686 batch_id=468: 100%|██████████| 469/469 [00:26<00:00, 17.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.2352, Accuracy: 9413/10000 (94%)\n",
            "\n",
            "epoch: 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.06830409914255142 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1522, Accuracy: 9597/10000 (96%)\n",
            "\n",
            "epoch: 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.040967147797346115 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0788, Accuracy: 9822/10000 (98%)\n",
            "\n",
            "epoch: 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.060575637966394424 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0958, Accuracy: 9751/10000 (98%)\n",
            "\n",
            "epoch: 5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.07910798490047455 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1270, Accuracy: 9653/10000 (97%)\n",
            "\n",
            "epoch: 6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.03485637530684471 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0972, Accuracy: 9734/10000 (97%)\n",
            "\n",
            "epoch: 7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.028562478721141815 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0749, Accuracy: 9807/10000 (98%)\n",
            "\n",
            "epoch: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.020091481506824493 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1005, Accuracy: 9720/10000 (97%)\n",
            "\n",
            "epoch: 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.030474001541733742 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0572, Accuracy: 9852/10000 (99%)\n",
            "\n",
            "epoch: 10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.007140759844332933 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0569, Accuracy: 9839/10000 (98%)\n",
            "\n",
            "epoch: 11\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.029873408377170563 batch_id=468: 100%|██████████| 469/469 [00:20<00:00, 22.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0572, Accuracy: 9835/10000 (98%)\n",
            "\n",
            "epoch: 12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.04716202989220619 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0652, Accuracy: 9793/10000 (98%)\n",
            "\n",
            "epoch: 13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.032739922404289246 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0600, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "epoch: 14\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.013936364091932774 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0475, Accuracy: 9861/10000 (99%)\n",
            "\n",
            "epoch: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.026295974850654602 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0443, Accuracy: 9872/10000 (99%)\n",
            "\n",
            "epoch: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05569593980908394 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0452, Accuracy: 9868/10000 (99%)\n",
            "\n",
            "epoch: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.012029538862407207 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0468, Accuracy: 9855/10000 (99%)\n",
            "\n",
            "epoch: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.014167357236146927 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0490, Accuracy: 9853/10000 (99%)\n",
            "\n",
            "epoch: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.008810898289084435 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 9905/10000 (99%)\n",
            "\n",
            "epoch: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.024968238547444344 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0469, Accuracy: 9878/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}