{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEGV2Eca7AEw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Target:\n",
        "We try to achieve 99.4 test accuracy within 8k params.\n",
        "We do this by experimenting with LR schedulers.\n",
        "\n",
        "\n",
        "Result:\n",
        "OneCycleLR and ExponentialLR were tried out.\n",
        "Various params of OneCycleLR were tried.\n",
        "\n",
        "num params: 8k\n",
        "train accuracy: 99.17\n",
        "test accuracy: > 99.35\n",
        "\n",
        "A stable test accuracy of > 99.35 was achieved\n",
        "\n",
        "Analysis:\n",
        "Good LR scheduling can improve accuracy towards the end.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BECzqFEr7Fi5"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYRcj9vt95ER",
        "outputId": "d5a9d35f-0939-4bb0-f526-771865c1380a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K9W9sFq7GHo"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    print('\\n#Train set: Average loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "        train_loss,\n",
        "        100. * correct / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('#Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxEHTpRk7Hdb",
        "outputId": "0cbfebca-f263-4cc6-b9ac-68b0fd60685d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "Num images in train: 60000\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "lr=0.01\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7, 7), fill=(1,)),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "print(f'Num images in train: {len(train_loader.dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wB2i6T67JI1",
        "outputId": "c9adb0a9-428a-488b-a706-7a059f599587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             120\n",
            "       BatchNorm2d-2           [-1, 12, 26, 26]              24\n",
            "           Dropout-3           [-1, 12, 26, 26]               0\n",
            "            Conv2d-4           [-1, 12, 24, 24]           1,308\n",
            "       BatchNorm2d-5           [-1, 12, 24, 24]              24\n",
            "           Dropout-6           [-1, 12, 24, 24]               0\n",
            "         MaxPool2d-7           [-1, 12, 12, 12]               0\n",
            "            Conv2d-8           [-1, 16, 10, 10]           1,744\n",
            "       BatchNorm2d-9           [-1, 16, 10, 10]              32\n",
            "          Dropout-10           [-1, 16, 10, 10]               0\n",
            "           Conv2d-11             [-1, 16, 8, 8]           2,320\n",
            "      BatchNorm2d-12             [-1, 16, 8, 8]              32\n",
            "          Dropout-13             [-1, 16, 8, 8]               0\n",
            "           Conv2d-14             [-1, 15, 6, 6]           2,175\n",
            "AdaptiveAvgPool2d-15             [-1, 15, 1, 1]               0\n",
            "           Conv2d-16             [-1, 10, 1, 1]             160\n",
            "================================================================\n",
            "Total params: 7,939\n",
            "Trainable params: 7,939\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.42\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.45\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-89d19ebaed0e>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "# from Step 2. Increase params to 8k. Use OneCycleLR scheduler.\n",
        "\n",
        "class Net_17(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 12, 3, padding=0)   #input - 28, Output 26, RF\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "        self.conv2 = nn.Conv2d(12, 12, 3, padding=0)   #input - 26, Output 24, RF\n",
        "        self.bn2 = nn.BatchNorm2d(12)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(12, 16, 3, padding=0)   #input - 24, Output 22, RF\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 16, 3, padding=0) #input - 11, Output 9, RF\n",
        "        self.bn4 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(16, 15, 3, padding=0) #input - 9, Output 7, RF\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.conv6 = nn.Conv2d(15, 10, 1)            #input - 7, Output 7, RF\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "        self.dropout4 = nn.Dropout(0.1)\n",
        "        self.dropout5 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = self.conv6(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "Net = Net_17\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "oclr_max_lr = 0.1\n",
        "num_epochs = 15\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "# scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=oclr_max_lr, steps_per_epoch=1, epochs=num_epochs)\n",
        "\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n",
        "\n",
        "##### For 20 epochs #######\n",
        "\n",
        "#epoch: 16\n",
        "#lr: 0.0188258346050237\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.12%\n",
        "#Test set: Average loss: 0.0201, Accuracy: 9939/10000 (99.39%)\n",
        "\n",
        "#epoch: 17\n",
        "#lr: 0.010908782242895003\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.17%\n",
        "#Test set: Average loss: 0.0186, Accuracy: 9944/10000 (99.44%)\n",
        "\n",
        "#epoch: 18\n",
        "#lr: 0.004951936798652629\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.23%\n",
        "#Test set: Average loss: 0.0179, Accuracy: 9946/10000 (99.46%)\n",
        "\n",
        "#epoch: 19\n",
        "#lr: 0.0012539993764912555\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.24%\n",
        "#Test set: Average loss: 0.0175, Accuracy: 9949/10000 (99.49%)\n",
        "\n",
        "#epoch: 20\n",
        "#lr: 4e-07\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.28%\n",
        "#Test set: Average loss: 0.0177, Accuracy: 9951/10000 (99.51%)\n",
        "\n",
        "\n",
        "############  For 15 epochs ##########\n",
        "\n",
        "\n",
        "#epoch: 11\n",
        "#lr: 0.03173322184988512\n",
        "#Train set: Average loss: 0.0003, Accuracy: 98.98%\n",
        "#Test set: Average loss: 0.0212, Accuracy: 9931/10000 (99.31%)\n",
        "\n",
        "#epoch: 12\n",
        "#lr: 0.0188258346050237\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.06%\n",
        "#Test set: Average loss: 0.0218, Accuracy: 9929/10000 (99.29%)\n",
        "\n",
        "#epoch: 13\n",
        "#lr: 0.008688426531955128\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.08%\n",
        "#Test set: Average loss: 0.0203, Accuracy: 9938/10000 (99.38%)\n",
        "\n",
        "#epoch: 14\n",
        "#lr: 0.002221750825254118\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.16%\n",
        "#Test set: Average loss: 0.0191, Accuracy: 9942/10000 (99.42%)\n",
        "\n",
        "#epoch: 15\n",
        "#lr: 4e-07\n",
        "#Train set: Average loss: 0.0002, Accuracy: 99.23%\n",
        "#Test set: Average loss: 0.0196, Accuracy: 9941/10000 (99.41%)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrVElH3QK9qk",
        "outputId": "b7848550-ff0f-4472-e932-70728756f746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             120\n",
            "       BatchNorm2d-2           [-1, 12, 26, 26]              24\n",
            "           Dropout-3           [-1, 12, 26, 26]               0\n",
            "            Conv2d-4           [-1, 12, 24, 24]           1,308\n",
            "       BatchNorm2d-5           [-1, 12, 24, 24]              24\n",
            "           Dropout-6           [-1, 12, 24, 24]               0\n",
            "         MaxPool2d-7           [-1, 12, 12, 12]               0\n",
            "            Conv2d-8           [-1, 16, 10, 10]           1,744\n",
            "       BatchNorm2d-9           [-1, 16, 10, 10]              32\n",
            "          Dropout-10           [-1, 16, 10, 10]               0\n",
            "           Conv2d-11             [-1, 16, 8, 8]           2,320\n",
            "      BatchNorm2d-12             [-1, 16, 8, 8]              32\n",
            "          Dropout-13             [-1, 16, 8, 8]               0\n",
            "           Conv2d-14             [-1, 15, 6, 6]           2,175\n",
            "AdaptiveAvgPool2d-15             [-1, 15, 1, 1]               0\n",
            "           Conv2d-16             [-1, 10, 1, 1]             160\n",
            "================================================================\n",
            "Total params: 7,939\n",
            "Trainable params: 7,939\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.42\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.45\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-89d19ebaed0e>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "# Try ExponentialLR\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "oclr_max_lr = 0.1\n",
        "num_epochs = 15\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "# scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "# scheduler = OneCycleLR(optimizer, max_lr=oclr_max_lr, steps_per_epoch=1, epochs=num_epochs)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n",
        "\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n",
        "\n",
        "#epoch: 13\n",
        "#lr: 0.0013841287200999988\n",
        "#Train set: Average loss: 0.0005, Accuracy: 98.27%\n",
        "#Test set: Average loss: 0.0442, Accuracy: 9868/10000 (98.68%)\n",
        "\n",
        "#epoch: 14\n",
        "#lr: 0.0009688901040699991\n",
        "#Train set: Average loss: 0.0005, Accuracy: 98.14%\n",
        "#Test set: Average loss: 0.0454, Accuracy: 9865/10000 (98.65%)\n",
        "\n",
        "#epoch: 15\n",
        "#lr: 0.0006782230728489993\n",
        "#Train set: Average loss: 0.0005, Accuracy: 98.19%\n",
        "#Test set: Average loss: 0.0434, Accuracy: 9869/10000 (98.69%)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpx3v_rfNnHG",
        "outputId": "1fb42e03-4e19-4d9e-b800-08523a5ae45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             120\n",
            "       BatchNorm2d-2           [-1, 12, 26, 26]              24\n",
            "           Dropout-3           [-1, 12, 26, 26]               0\n",
            "            Conv2d-4           [-1, 12, 24, 24]           1,308\n",
            "       BatchNorm2d-5           [-1, 12, 24, 24]              24\n",
            "           Dropout-6           [-1, 12, 24, 24]               0\n",
            "         MaxPool2d-7           [-1, 12, 12, 12]               0\n",
            "            Conv2d-8           [-1, 16, 10, 10]           1,744\n",
            "       BatchNorm2d-9           [-1, 16, 10, 10]              32\n",
            "          Dropout-10           [-1, 16, 10, 10]               0\n",
            "           Conv2d-11             [-1, 16, 8, 8]           2,320\n",
            "      BatchNorm2d-12             [-1, 16, 8, 8]              32\n",
            "          Dropout-13             [-1, 16, 8, 8]               0\n",
            "           Conv2d-14             [-1, 15, 6, 6]           2,175\n",
            "AdaptiveAvgPool2d-15             [-1, 15, 1, 1]               0\n",
            "           Conv2d-16             [-1, 10, 1, 1]             160\n",
            "================================================================\n",
            "Total params: 7,939\n",
            "Trainable params: 7,939\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.42\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.45\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-89d19ebaed0e>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "Net = Net_17\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "oclr_max_lr = 0.1\n",
        "num_epochs = 15\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "# scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=oclr_max_lr, steps_per_epoch=1, epochs=num_epochs, pct_start=0.2)\n",
        "\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4Dplxu6IUPL"
      },
      "outputs": [],
      "source": [
        "# model = torch.nn.Linear(2, 1)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n",
        "# lrs = []\n",
        "\n",
        "\n",
        "# for i in range(15):\n",
        "#     optimizer.step()\n",
        "#     lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "#     print(\"lr: \", optimizer.param_groups[0][\"lr\"])\n",
        "#     scheduler.step()\n",
        "\n",
        "# plt.plot(lrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VprgbfQ1q3cz",
        "outputId": "fe320346-2d02-4b15-cc9e-b389349e6e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             120\n",
            "       BatchNorm2d-2           [-1, 12, 26, 26]              24\n",
            "           Dropout-3           [-1, 12, 26, 26]               0\n",
            "            Conv2d-4           [-1, 12, 24, 24]           1,308\n",
            "       BatchNorm2d-5           [-1, 12, 24, 24]              24\n",
            "           Dropout-6           [-1, 12, 24, 24]               0\n",
            "         MaxPool2d-7           [-1, 12, 12, 12]               0\n",
            "            Conv2d-8           [-1, 16, 10, 10]           1,744\n",
            "       BatchNorm2d-9           [-1, 16, 10, 10]              32\n",
            "          Dropout-10           [-1, 16, 10, 10]               0\n",
            "           Conv2d-11             [-1, 16, 8, 8]           2,320\n",
            "      BatchNorm2d-12             [-1, 16, 8, 8]              32\n",
            "          Dropout-13             [-1, 16, 8, 8]               0\n",
            "           Conv2d-14             [-1, 15, 6, 6]           2,175\n",
            "AdaptiveAvgPool2d-15             [-1, 15, 1, 1]               0\n",
            "           Conv2d-16             [-1, 10, 1, 1]             160\n",
            "================================================================\n",
            "Total params: 7,939\n",
            "Trainable params: 7,939\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.42\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.45\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-89d19ebaed0e>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "Net = Net_17\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "oclr_max_lr = 0.1\n",
        "num_epochs = 15\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=oclr_max_lr, steps_per_epoch=1,\n",
        "                       epochs=num_epochs, pct_start=0.3)\n",
        "\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-8Jkt9vH9fnq",
        "outputId": "6a31409b-4add-4ad6-ad5a-4fcbed756d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#epoch: 1\n",
            "#lr: 0.0040000000000000036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-17-89d19ebaed0e>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "loss=0.17490625381469727 batch_id=468: 100%|██████████| 469/469 [00:33<00:00, 13.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0080, Accuracy: 65.27%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.2518, Accuracy: 9222/10000 (92.22%)\n",
            "\n",
            "#epoch: 2\n",
            "#lr: 0.022072489510780793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.0644674226641655 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0013, Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0639, Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "#epoch: 3\n",
            "#lr: 0.0626810048299031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.11920801550149918 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0008, Accuracy: 96.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0639, Accuracy: 9783/10000 (97.83%)\n",
            "\n",
            "#epoch: 4\n",
            "#lr: 0.09524650565931612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.05484486743807793 batch_id=468: 100%|██████████| 469/469 [00:26<00:00, 17.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0006, Accuracy: 97.63%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0411, Accuracy: 9884/10000 (98.84%)\n",
            "\n",
            "#epoch: 5\n",
            "#lr: 0.09944154354509119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.07897200435400009 batch_id=468: 100%|██████████| 469/469 [00:26<00:00, 17.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0005, Accuracy: 98.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0310, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "#epoch: 6\n",
            "#lr: 0.09504846320134738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.030147211626172066 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0004, Accuracy: 98.33%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0351, Accuracy: 9896/10000 (98.96%)\n",
            "\n",
            "#epoch: 7\n",
            "#lr: 0.08665264698111695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.05822373926639557 batch_id=468: 100%|██████████| 469/469 [00:26<00:00, 18.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0004, Accuracy: 98.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0317, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "#epoch: 8\n",
            "#lr: 0.0750001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.058729302138090134 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0004, Accuracy: 98.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0329, Accuracy: 9903/10000 (99.03%)\n",
            "\n",
            "#epoch: 9\n",
            "#lr: 0.06112620219362893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.025506997480988503 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0003, Accuracy: 98.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0329, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "#epoch: 10\n",
            "#lr: 0.046263710266697504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.06617381423711777 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0003, Accuracy: 98.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0258, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "#epoch: 11\n",
            "#lr: 0.03173322184988512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.0950298085808754 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0003, Accuracy: 98.84%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0222, Accuracy: 9927/10000 (99.27%)\n",
            "\n",
            "#epoch: 12\n",
            "#lr: 0.0188258346050237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.017018385231494904 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0002, Accuracy: 99.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0197, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "#epoch: 13\n",
            "#lr: 0.008688426531955128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.014849289320409298 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0002, Accuracy: 99.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0209, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "#epoch: 14\n",
            "#lr: 0.002221750825254118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.05150482431054115 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0002, Accuracy: 99.12%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0199, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "#epoch: 15\n",
            "#lr: 4e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.019408313557505608 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Train set: Average loss: 0.0002, Accuracy: 99.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Test set: Average loss: 0.0194, Accuracy: 9937/10000 (99.37%)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f073059d480>]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lrs = []\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print(f'#epoch: {epoch}')\n",
        "    print(f'#lr: {optimizer.param_groups[0][\"lr\"]}')\n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "plt.plot(lrs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
